name: Export Models

on:
  workflow_dispatch:
    inputs:
      adapter_path:
        description: 'Path to adapter directory (e.g., phi3mini4k-minimal-r32-a64-e20-20250914-132416)'
        type: string
        required: true
      export_formats:
        description: 'Export formats'
        type: choice
        options:
          - 'all'
          - 'vllm'
          - 'ollama'
        default: 'all'
      ollama_quantization:
        description: 'Ollama quantization format'
        type: choice
        options:
          - 'q4_k_m'
          - 'q5_k_m'
          - 'q8_0'
          - 'f16'
        default: 'q4_k_m'
      push_to_hub:
        description: 'Push to Hugging Face Hub'
        type: boolean
        default: false
      hub_repo:
        description: 'Hugging Face repo name (if pushing)'
        type: string
        default: ''

jobs:
  export-vllm:
    name: Export vLLM
    if: inputs.export_formats == 'all' || inputs.export_formats == 'vllm'
    runs-on: [self-hosted, Linux, X64, wsl2]
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Setup Python environment
        run: |
          uv venv --python 3.10
          uv sync --all-extras

      - name: Verify adapter exists
        run: |
          if [ ! -d "avro-phi3-adapters/${{ inputs.adapter_path }}" ]; then
            echo "Error: Adapter directory not found: avro-phi3-adapters/${{ inputs.adapter_path }}"
            exit 1
          fi
          echo "Found adapter directory"
          ls -la "avro-phi3-adapters/${{ inputs.adapter_path }}"

      - name: Export for vLLM
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          # Note: merge_and_export.py doesn't support direct hub push yet
          # Just export locally for now
          uv run python merge_and_export.py \
            --adapter-path "avro-phi3-adapters/${{ inputs.adapter_path }}" \
            --format vllm

          # Get export directory
          EXPORT_DIR=$(ls -td exports/*-vllm-* | head -1)
          echo "VLLM_EXPORT_DIR=$EXPORT_DIR" >> $GITHUB_ENV
          echo "Exported to: $EXPORT_DIR"

      - name: Package vLLM model
        run: |
          cd ${{ env.VLLM_EXPORT_DIR }}
          tar -czf ../vllm-${{ inputs.adapter_path }}.tar.gz .
          echo "Created package: vllm-${{ inputs.adapter_path }}.tar.gz"

      - name: Upload vLLM artifact
        uses: actions/upload-artifact@v4.3.3
        with:
          name: vllm-${{ inputs.adapter_path }}
          path: exports/vllm-${{ inputs.adapter_path }}.tar.gz
          retention-days: 30

  export-ollama:
    name: Export Ollama
    if: inputs.export_formats == 'all' || inputs.export_formats == 'ollama'
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Setup Docker
        run: |
          docker --version
          docker compose version

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.local/bin" >> $GITHUB_PATH

      - name: Setup Python environment
        run: |
          uv venv --python 3.10
          uv sync

      - name: Verify adapter exists
        run: |
          if [ ! -d "avro-phi3-adapters/${{ inputs.adapter_path }}" ]; then
            echo "Error: Adapter directory not found: avro-phi3-adapters/${{ inputs.adapter_path }}"
            exit 1
          fi
          echo "Found adapter directory"

      - name: Export for Ollama
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          echo "Exporting with ${{ inputs.ollama_quantization }} quantization..."

          uv run python export_ollama_docker.py \
            "avro-phi3-adapters/${{ inputs.adapter_path }}" \
            --quantize "${{ inputs.ollama_quantization }}"

          # Get export directory
          EXPORT_DIR=$(ls -td exports/*-ollama-docker-* | head -1)
          echo "OLLAMA_EXPORT_DIR=$EXPORT_DIR" >> $GITHUB_ENV
          echo "Exported to: $EXPORT_DIR"

      - name: Verify GGUF files
        run: |
          cd ${{ env.OLLAMA_EXPORT_DIR }}
          echo "Contents of export directory:"
          ls -lh
          if [ ! -f "model.gguf" ] && [ ! -f "model-${{ inputs.ollama_quantization }}.gguf" ]; then
            echo "Error: No GGUF file found!"
            exit 1
          fi

      - name: Package Ollama model
        run: |
          cd ${{ env.OLLAMA_EXPORT_DIR }}
          tar -czf ../ollama-${{ inputs.ollama_quantization }}-${{ inputs.adapter_path }}.tar.gz .
          echo "Created package: ollama-${{ inputs.ollama_quantization }}-${{ inputs.adapter_path }}.tar.gz"

      - name: Upload Ollama artifact
        uses: actions/upload-artifact@v4.3.3
        with:
          name: ollama-${{ inputs.ollama_quantization }}-${{ inputs.adapter_path }}
          path: exports/ollama-${{ inputs.ollama_quantization }}-${{ inputs.adapter_path }}.tar.gz
          retention-days: 30

      - name: Push to Hugging Face Hub
        if: inputs.push_to_hub == true && inputs.hub_repo != ''
        env:
          HF_TOKEN: ${{ secrets.HF_TOKEN }}
        run: |
          pip install huggingface-hub

          cat > upload_to_hub.py << 'EOF'
          import os
          from huggingface_hub import HfApi, create_repo

          api = HfApi()
          repo_id = "${{ inputs.hub_repo }}-ollama-${{ inputs.ollama_quantization }}"

          # Create repo if it doesn't exist
          try:
              create_repo(repo_id, exist_ok=True, repo_type="model")
          except:
              pass

          # Upload GGUF file
          export_dir = os.environ['OLLAMA_EXPORT_DIR']
          gguf_files = [f for f in os.listdir(export_dir) if f.endswith('.gguf')]

          for gguf_file in gguf_files:
              api.upload_file(
                  path_or_fileobj=os.path.join(export_dir, gguf_file),
                  path_in_repo=gguf_file,
                  repo_id=repo_id,
                  repo_type="model"
              )

          # Upload Modelfile and other configs
          for file in ['Modelfile', 'docker-compose.yml', 'README.md']:
              file_path = os.path.join(export_dir, file)
              if os.path.exists(file_path):
                  api.upload_file(
                      path_or_fileobj=file_path,
                      path_in_repo=file,
                      repo_id=repo_id,
                      repo_type="model"
                  )

          print(f"Uploaded to: https://huggingface.co/{repo_id}")
          EOF

          python upload_to_hub.py

  create-deployment-package:
    name: Create Deployment Package
    needs: [export-vllm, export-ollama]
    if: always() && (needs.export-vllm.result == 'success' || needs.export-ollama.result == 'success')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download all artifacts
        uses: actions/download-artifact@v4.1.7
        with:
          path: ./artifacts/

      - name: Create combined package
        run: |
          mkdir -p deployment-package

          # Copy all artifacts
          cp artifacts/*/*.tar.gz deployment-package/ 2>/dev/null || true

          # Create deployment instructions
          cat > deployment-package/DEPLOY.md << 'EOF'
          # Deployment Package

          ## Contents
          This package contains exported models in various formats.

          ## vLLM Deployment
          ```bash
          tar -xzf vllm-*.tar.gz
          vllm serve ./model --dtype auto
          ```

          ## Ollama Deployment
          ```bash
          tar -xzf ollama-*.tar.gz
          docker compose up -d
          docker compose exec ollama ollama run <model-name>
          ```

          ## Files
          EOF

          ls -lh deployment-package/*.tar.gz >> deployment-package/DEPLOY.md || echo "No files found" >> deployment-package/DEPLOY.md

          # Create checksums
          cd deployment-package
          for file in *.tar.gz; do
            if [ -f "$file" ]; then
              sha256sum "$file" > "$file.sha256"
            fi
          done
          cd ..

          # Create final archive
          tar -czf deployment-${{ inputs.adapter_path }}.tar.gz deployment-package/

      - name: Upload deployment package
        uses: actions/upload-artifact@v4.3.3
        with:
          name: deployment-${{ inputs.adapter_path }}
          path: deployment-${{ inputs.adapter_path }}.tar.gz
          retention-days: 30